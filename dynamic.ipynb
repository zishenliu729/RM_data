{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe7506c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import drjit as dr\n",
    "# Import or install Sionna\n",
    "try:\n",
    "    import sionna.rt\n",
    "except ImportError as e:\n",
    "    import os\n",
    "    os.system(\"pip install sionna-rt\")\n",
    "    import sionna.rt\n",
    "\n",
    "no_preview = False # Toggle to False to use the preview widget\n",
    "                  # instead of rendering for scene visualization\n",
    "\n",
    "from sionna.rt import load_scene, PlanarArray, Transmitter, Receiver, Camera,\\\n",
    "                      RadioMapSolver, PathSolver,transform_mesh\n",
    "from sionna.rt.utils import r_hat, subcarrier_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf173079",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = load_scene(\"Hong Hum_256.xml\",\n",
    "                   merge_shapes=False)\n",
    "\n",
    "\n",
    "# Configure a transmitter that is located at the front of \"car_2\"\n",
    "scene.add(Transmitter(\"tx\", position=[6,18,1.5], orientation=[np.pi,0,0]))\n",
    "scene.tx_array = PlanarArray(num_rows=1, num_cols=1, pattern=\"tr38901\", polarization=\"V\")\n",
    "scene.rx_array = scene.tx_array\n",
    "\n",
    "# Create radio map solver\n",
    "rm_solver = RadioMapSolver()\n",
    "                # rm_show_color_bar=True,\n",
    "# rm = rm_solver(scene=scene,\n",
    "#                    samples_per_tx=20**6,\n",
    "#                    refraction=True,\n",
    "#                    max_depth=10,\n",
    "#                    cell_size=[2,2])\n",
    "# cam =  Camera(position=[-14,35,450], look_at=[-14,35,0])\n",
    "# # scene.preview(radio_map=rm,\n",
    "# #                 rm_vmax=-40, rm_vmin=-150)\n",
    "# scene.render_to_file(camera=cam,  filename=\"HH.png\", radio_map=rm,\n",
    "#                      resolution=(256,256),\n",
    "#                 num_samples=1024,\n",
    "#                 rm_vmin=-140)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784cdf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_masks(rm_mask, building_mask, car_mask):\n",
    "    \"\"\"\n",
    "    处理三张mask图像：使mask3在mask1或mask2为1的位置均为0\n",
    "    \n",
    "    参数:\n",
    "        mask1, mask2, mask3: 输入的灰度图mask（numpy数组），元素值为0或1，\n",
    "                           形状需完全相同 (height, width)\n",
    "    返回:\n",
    "        处理后的mask3（numpy数组）\n",
    "    \"\"\"\n",
    "    # 检查三张图尺寸是否一致\n",
    "    if not (rm_mask.shape == building_mask.shape == car_mask.shape):\n",
    "        raise ValueError(\"三张mask图像的尺寸必须完全相同！\")\n",
    "    \n",
    "    # 步骤1：找到mask1或mask2中为1的位置（逻辑或运算）\n",
    "    # 注：若mask是0-255的灰度图，需先转换为0/1（如 mask1 == 255）\n",
    "    # 这里假设输入mask已是0/1的二值图\n",
    "    mask_obstacle = np.logical_or(car_mask, building_mask)  # 结果为布尔数组，True表示需要清零的位置\n",
    "    \n",
    "    # 步骤2：将mask3中上述位置设为0\n",
    "    processed_mask3 = rm_mask.copy()  # 避免修改原数组\n",
    "    processed_mask3[mask_obstacle] = 0  # 符合条件的位置强制设为0\n",
    "    \n",
    "    return processed_mask3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "571004c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gray_generate(radio_map,metric,file_name,db_scale: bool = True):\n",
    "    \n",
    "    rm_real = radio_map.path_gain.numpy().squeeze(axis=0)\n",
    "    if metric==\"rss\" and db_scale:\n",
    "        rm_values *= 1000\n",
    "    valid = np.logical_and(rm_real > 0., np.isfinite(rm_real))\n",
    "    opacity = valid.astype(np.float32)\n",
    "    any_valid = np.any(valid)\n",
    "    rm_real[valid] = 10. * np.log10(rm_real[valid])\n",
    "\n",
    "    vmin = rm_real[valid].min() if any_valid else 0\n",
    "\n",
    "    vmax = rm_real[valid].max() if any_valid else 0\n",
    "    normalizer = matplotlib.colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "    color_map = matplotlib.colormaps.get_cmap('gray')\n",
    "    texture = color_map(normalizer(rm_real))\n",
    "    # Eliminate alpha channel\n",
    "    texture = texture[..., :3]\n",
    "    # Colors from the color map are gamma-compressed, go back to linear\n",
    "    texture = np.power(texture, 2.2)\n",
    "     # Pre-multiply alpha to avoid fringe\n",
    "    texture *= opacity[..., None]\n",
    "\n",
    "    texture_uint8 = (texture * 255).astype(np.uint8)\n",
    "    texture_single = texture_uint8[..., 0] \n",
    "    return plt.imsave(file_name, texture_single, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "910ae960",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ground_3d_to_topview_pixel(scene, ground_vertices, image_width, image_height):\n",
    "    \"\"\"\n",
    "    将地面3D顶点坐标（z≈0）转换为俯视图的像素坐标（基于场景整体边界）\n",
    "    \n",
    "    参数:\n",
    "        scene: 场景对象（用于获取整体边界）\n",
    "        ground_vertices: 形状为 (N, 3) 的numpy数组，存储地面顶点的3D坐标 (x, y, z)\n",
    "        image_width: 俯视图宽度（像素）\n",
    "        image_height: 俯视图高度（像素）\n",
    "    \n",
    "    返回:\n",
    "        形状为 (N, 2) 的numpy数组，存储像素坐标 (u, v)\n",
    "    \"\"\"\n",
    "    # 1. 提取x和y坐标（忽略z，地面z≈0）\n",
    "    # 修正：提取前两列（x和y），形状为 (N, 2)\n",
    "    # loc = ground_vertices[:, :2]  # 改为[:, :2]，获取(x, y)\n",
    "    \n",
    "    # 2. 获取场景整体边界（x和y方向）\n",
    "    scene_bbox = scene.mi_scene.bbox()\n",
    "    # 处理空场景的边界（避免±inf导致计算错误）\n",
    "    scene_min = scene_bbox.min\n",
    "    scene_min = dr.select(dr.isinf(scene_min), -1.0, scene_min)  # 用dr.Vector3f统一处理\n",
    "    scene_max = scene_bbox.max\n",
    "    scene_max = dr.select(dr.isinf(scene_max), 1.0, scene_max)\n",
    "    \n",
    "    # 提取x和y方向的边界（转换为numpy数组便于计算）\n",
    "    # 注意：根据实际API调整属性访问方式（可能是.x/.y或[0]/[1]）\n",
    "    x_min, y_min = scene_min.x, scene_min.y\n",
    "    x_max, y_max = scene_max.x, scene_max.y\n",
    "    \n",
    "    # 处理边界相同的特殊情况（避免除零）\n",
    "    if x_max == x_min:\n",
    "        x_max = x_min + 1e-6\n",
    "    if y_max == y_min:\n",
    "        y_max = y_min + 1e-6\n",
    "    \n",
    "    # 3. 计算x和y方向的尺寸\n",
    "    size_x = x_max - x_min\n",
    "    size_y = y_max - y_min\n",
    "    \n",
    "    pixel_coords = {}  # 存储结果：{网格ID: 像素坐标数组(N,2)}\n",
    "    for mesh_id, vertices in ground_vertices.items():\n",
    "        # 提取当前网格顶点的x和y坐标（忽略z）\n",
    "        # vertices形状为(N,3)，取前两列得到(N,2)的(x,y)\n",
    "        loc = vertices[:, :2]\n",
    "        \n",
    "        # 归一化到[0,1]范围\n",
    "        norm_x = (loc[:, 0] - x_min) / size_x\n",
    "        norm_y = (loc[:, 1] - y_min) / size_y\n",
    "        \n",
    "        # 映射到像素坐标\n",
    "        pixel_u = norm_x * (image_width - 1)\n",
    "        pixel_v = norm_y * (image_height - 1)  # 若需翻转y轴，改为(1 - norm_y) * ...\n",
    "        \n",
    "        # 转换为整数像素坐标，存入结果字典\n",
    "        pixel_coords[mesh_id] = np.column_stack([pixel_u, pixel_v]).astype(int)\n",
    "    \n",
    "    # 转换为整数像素坐标\n",
    "    return pixel_coords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e90163aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def world_to_pixel(world_points, sensor, image_width, image_height):\n",
    "    \"\"\"\n",
    "    将3D世界坐标转换为2D像素坐标\n",
    "    :param world_points: 形状为 (N, 3) 的numpy数组，存储3D顶点坐标 (x, y, z)\n",
    "    :param sensor: Mitsuba传感器（相机）对象\n",
    "    :param image_width: 渲染图片的宽度（像素）\n",
    "    :param image_height: 渲染图片的高度（像素）\n",
    "    :return: 形状为 (N, 2) 的numpy数组，存储像素坐标 (u, v)\n",
    "    \"\"\"\n",
    "    # 1. 获取相机的视图变换矩阵（世界坐标 → 相机坐标）\n",
    "    view_transform = sensor.world_transform\n",
    "    # 2. 获取相机的投影矩阵（相机坐标 → 归一化设备坐标NDC）\n",
    "    proj_transform = sensor.projection_transform()\n",
    "    \n",
    "    # 3. 转换3D点为齐次坐标（添加w=1）\n",
    "    homogeneous_points = np.hstack([world_points, np.ones((len(world_points), 1))])  # 形状 (N, 4)\n",
    "    \n",
    "    # 4. 应用视图变换（世界坐标 → 相机坐标）\n",
    "    camera_points = view_transform.transform_points(homogeneous_points)  # 结果仍是齐次坐标 (N, 4)\n",
    "    \n",
    "    # 5. 应用投影变换（相机坐标 → NDC坐标，范围[-1,1]）\n",
    "    ndc_points = proj_transform.transform_points(camera_points)  # (N, 4)\n",
    "    \n",
    "    # 6. 透视除法（齐次坐标转非齐次）\n",
    "    ndc_x = ndc_points[:, 0] / ndc_points[:, 3]\n",
    "    ndc_y = ndc_points[:, 1] / ndc_points[:, 3]\n",
    "    \n",
    "    # 7. NDC坐标 → 像素坐标（[-1,1] → [0, width/height]）\n",
    "    # 注意：图像坐标系中y轴向下，需要翻转\n",
    "    pixel_u = (ndc_x + 1) * 0.5 * image_width\n",
    "    pixel_v = (1 - (ndc_y + 1) * 0.5) * image_height  # 翻转y轴\n",
    "    \n",
    "    # 8. 转换为整数像素坐标（可选，根据需求保留浮点或取整）\n",
    "    return np.column_stack([pixel_u, pixel_v]).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0aa2e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_2d_vertices(scene, obj_type, with_all_vert):\n",
    "    \"\"\"\n",
    "    获取场景中指定类型物体的地面顶点3D坐标\n",
    "    \n",
    "    参数:\n",
    "        scene: 场景对象\n",
    "        obj_type: 物体类型，可选值: \"only_building\"|\"only_car\"|\"both\"\n",
    "        with_all_vert: 是否返回所有顶点坐标\n",
    "    \n",
    "    返回:\n",
    "        根据参数组合返回不同的顶点数组组合\n",
    "    \"\"\"\n",
    "    # 验证输入参数有效性\n",
    "    valid_types = {\"only_building\", \"only_car\", \"both\"}\n",
    "    if obj_type not in valid_types:\n",
    "        raise ValueError(f\"obj_type必须是{valid_types}中的一种，当前为{obj_type}\")\n",
    "    \n",
    "    # 初始化存储容器\n",
    "    all_vertices = {}                 # 所有顶点\n",
    "    ground_vertices_buildings = {}     # 建筑物地面顶点\n",
    "    ground_vertices_cars = {}          # 车辆地面顶点\n",
    "\n",
    "    # 一次遍历完成所有顶点收集，减少重复计算\n",
    "    for sh in scene.mi_scene.shapes():\n",
    "        # 只处理网格类型\n",
    "        if not sh.is_mesh():\n",
    "            continue\n",
    "        mesh_id = sh.id()\n",
    "        # 获取并转换顶点坐标 (3D世界坐标)\n",
    "        # 注意：根据实际API调整顶点缓冲区的获取方式\n",
    "        vertices_buffer = sh.vertex_positions_buffer()\n",
    "        vertices_np = np.array(vertices_buffer, dtype=np.float32).reshape(-1, 3)\n",
    "        all_vertices[mesh_id] = vertices_np\n",
    "        \n",
    "        # 获取材质名称用于区分物体类型\n",
    "        mat_name = sh.bsdf().radio_material.name\n",
    "        \n",
    "        # 只对目标类型物体进行地面顶点筛选\n",
    "        process_building = (obj_type in [\"only_building\", \"both\"]) and (mat_name == \"itu_brick\")\n",
    "        process_car = (obj_type in [\"only_car\", \"both\"]) and (mat_name == \"itu_metal\")\n",
    "        \n",
    "        if not (process_building or process_car):\n",
    "            continue\n",
    "        \n",
    "        # 计算地面阈值（z轴为高度方向）\n",
    "        # 这里使用当前网格的z最小值作为局部地面参考（更精准）\n",
    "        local_min_z = np.min(vertices_np[:, 2])\n",
    "        epsilon = 0.1\n",
    "        z_min = local_min_z - epsilon\n",
    "        z_max = local_min_z + epsilon\n",
    "        \n",
    "        # 筛选地面顶点\n",
    "        is_ground = (vertices_np[:, 2] >= z_min) & (vertices_np[:, 2] <= z_max)\n",
    "        ground_vertices = vertices_np[is_ground]\n",
    "        \n",
    "        # 根据物体类型分类存储\n",
    "        if process_building:\n",
    "            ground_vertices_buildings[mesh_id] = ground_vertices\n",
    "        if process_car:\n",
    "            ground_vertices_cars[mesh_id] = ground_vertices\n",
    "    \n",
    "    \n",
    "    \n",
    "    # 根据参数组合返回结果\n",
    "    if with_all_vert:\n",
    "        if obj_type == \"only_building\":\n",
    "            return all_vertices, ground_vertices_buildings\n",
    "        elif obj_type == \"only_car\":\n",
    "            return all_vertices, ground_vertices_cars\n",
    "        else:  # both\n",
    "            return all_vertices, ground_vertices_buildings, ground_vertices_cars\n",
    "    else:\n",
    "        if obj_type == \"only_building\":\n",
    "            return ground_vertices_buildings\n",
    "        elif obj_type == \"only_car\":\n",
    "            return ground_vertices_cars\n",
    "        else:  # both\n",
    "            return ground_vertices_buildings, ground_vertices_cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b9b730",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_mask(vertices_dict, image_width, image_height):\n",
    "    \"\"\"\n",
    "    创建建筑物地面区域的掩码图像（适配字典格式输入）\n",
    "    \n",
    "    参数:\n",
    "        building_vertices_dict: 字典格式 {网格ID: 像素坐标数组(N,2)}，\n",
    "                               每个数组存储一个建筑物的地面顶点像素坐标\n",
    "        image_width: 图像宽度（像素）\n",
    "        image_height: 图像高度（像素）\n",
    "    \n",
    "    返回:\n",
    "        灰度图像数组（0为背景，1为建筑物内部），形状为 (image_height, image_width)\n",
    "    \"\"\"\n",
    "    # 创建空白图像（初始全为0）\n",
    "    mask = np.zeros((image_height, image_width), dtype=np.uint8)\n",
    "    \n",
    "    # 遍历字典中的每个建筑物顶点数组（忽略键，只处理值）\n",
    "    for vertices in vertices_dict.values():\n",
    "        # 过滤超出图像范围的顶点（避免填充错误）\n",
    "        valid_vertices = vertices[\n",
    "            (vertices[:, 0] >= 0) & (vertices[:, 0] < image_width) &\n",
    "            (vertices[:, 1] >= 0) & (vertices[:, 1] < image_height)\n",
    "        ]\n",
    "        \n",
    "        if len(valid_vertices) < 3:  # 至少需要3个点才能构成多边形\n",
    "            continue\n",
    "        \n",
    "        # 转换为OpenCV需要的格式（int32类型的二维数组）\n",
    "        pts = valid_vertices.astype(np.int32).reshape((-1, 1, 2))\n",
    "        \n",
    "        # 填充多边形内部（值设为1）\n",
    "        cv2.fillPoly(mask, [pts], color=1)\n",
    "        \n",
    "        # 旋转后图像尺寸会变为 (原宽度, 原高度)\n",
    "        rotated = cv2.rotate(mask, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "    \n",
    "        # 步骤2：沿height中心轴（垂直中轴线）镜像翻转（水平翻转）\n",
    "        # 翻转后图像左右颠倒\n",
    "        flipped = cv2.flip(rotated, flipCode=1)\n",
    "    \n",
    "    return flipped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0cd5e49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "displacement_vec_x_p = [10,0,0]\n",
    "displacement_vec_x_n = [-10,0,0]\n",
    "displacement_vec_y_p = [0,10,0]\n",
    "displacement_vec_y_n = [0,-10,0]\n",
    "num_displacements = 2\n",
    "image_width = 256\n",
    "image_height = 256\n",
    "cam =  Camera(position=[-14,35,450], look_at=[-14,35,0])\n",
    "for i in range(num_displacements+1): \n",
    "    rm = rm_solver(scene=scene,\n",
    "                    samples_per_tx=20**6,\n",
    "                    refraction=True,\n",
    "                    max_depth=10,\n",
    "                    cell_size=[1,1])\n",
    "    \n",
    "    gray_generate(rm,metric=\"path_gain\",file_name=f\"/home/super/Zishen/RM_data_sio/RM_data/path_gain_HH_{i}.png\")\n",
    "    ground_vertices, ground_vertices_buildings_np, ground_vertices_cars_np = get_2d_vertices(scene=scene, obj_type=\"both\", with_all_vert=True)\n",
    "    building_pixel_coords = ground_3d_to_topview_pixel(scene = scene,\n",
    "                                                        ground_vertices=ground_vertices_buildings_np, \n",
    "                                                        image_width=image_width, \n",
    "                                                        image_height=image_height)\n",
    "    car_pixel_coords = ground_3d_to_topview_pixel(scene = scene,\n",
    "                                                        ground_vertices=ground_vertices_cars_np, \n",
    "                                                        image_width=image_width, \n",
    "                                                        image_height=image_height)\n",
    "    building_mask = create_mask(building_pixel_coords, image_width, image_height)\n",
    "    car_mask = create_mask(car_pixel_coords, image_width, image_height)\n",
    "    cv2.imwrite(\"building_ground_mask.png\", building_mask * 255)\n",
    "    cv2.imwrite(f\"cars_{i}.png\", car_mask * 255)\n",
    "    \n",
    "    \n",
    "\n",
    "    scene.render_to_file(camera=cam,  filename=f\"HH_{i}.png\", radio_map=rm,\n",
    "                     resolution=(256,256),\n",
    "                num_samples=1024,\n",
    "                rm_vmin=-140)\n",
    "    j= 1\n",
    "    formatted_num = f\"{j:03d}\"\n",
    "    a = scene.get(f\"mesh-car_x_p_{formatted_num}\")\n",
    "    b = scene.get(f\"mesh-car_x_n_{formatted_num}\")\n",
    "    c = scene.get(f\"mesh-car_y_p_{formatted_num}\")\n",
    "    d = scene.get(f\"mesh-car_y_n_{formatted_num}\")\n",
    "    while a is not None or b is not None or c is not None or d is not None:\n",
    "\n",
    "        # Compute and render a coverage map at 0.5m above the ground\n",
    "        \n",
    "\n",
    "        j += 1\n",
    "        formatted_num = f\"{j:03d}\"\n",
    "        a = scene.get(f\"mesh-car_x_p_{formatted_num}\")\n",
    "        b = scene.get(f\"mesh-car_x_n_{formatted_num}\")\n",
    "        c = scene.get(f\"mesh-car_y_p_{formatted_num}\")\n",
    "        d = scene.get(f\"mesh-car_y_n_{formatted_num}\")\n",
    "\n",
    "        if a != None:\n",
    "            scene.get(f\"mesh-car_x_p_{formatted_num}\").position += displacement_vec_x_p\n",
    "        if b != None:\n",
    "            scene.get(f\"mesh-car_x_n_{formatted_num}\").position += displacement_vec_x_n\n",
    "        if c != None:\n",
    "            scene.get(f\"mesh-car_y_p_{formatted_num}\").position += displacement_vec_y_p\n",
    "        if d != None:\n",
    "            scene.get(f\"mesh-car_y_n_{formatted_num}\").position += displacement_vec_y_n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_zishen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
